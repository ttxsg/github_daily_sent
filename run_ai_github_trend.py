import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import google.generativeai as genai
import os
import re
import asyncio
from crawl4ai import AsyncWebCrawler
# æå– GitHub URL ä¸­çš„ owner å’Œ repo
def extract_owner_repo(url):
    match = re.match(r'https://github.com/([^/]+)/([^/]+)', url)
    if match:
        owner = match.group(1)
        repo = match.group(2)
        return owner, repo
    else:
        return None, None

# è·å– GitHub ä»“åº“çš„ README å†…å®¹ï¼ˆçº¯æ–‡æœ¬ï¼‰
def get_github_readme(url_input):
    # url = f"https://github.com/{owner}/{repo}/blob/main/README.md"  # ä½¿ç”¨ raw æ¥è·å–åŸå§‹ Markdown æ–‡ä»¶
    # response = requests.get(url_input)
    response = requests.get(url, verify=False)
    if response.status_code == 200:
        return response.text  # ç›´æ¥è¿”å›åŸå§‹çš„ Markdown å†…å®¹
    else:
        return f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"

# æå–æ‰€æœ‰å›¾ç‰‡é“¾æ¥
def extract_image_links(readme_markdown):
    image_links = re.findall(r'!\[.*?\]\((https?://[^\)]+\.(?:png|jpg|jpeg|gif|svg))\)', readme_markdown)
    return image_links

# å‹ç¼©å›¾ç‰‡
def compress_image(img_data, quality=10):
    try:
        # ä½¿ç”¨ PIL æ‰“å¼€å›¾ç‰‡æ•°æ®
        image = Image.open(BytesIO(img_data))
        
        # å¦‚æœå›¾ç‰‡æ˜¯è°ƒè‰²æ¿æ¨¡å¼ (P)ï¼Œåˆ™è½¬æ¢ä¸º RGB æ¨¡å¼
        if image.mode == 'P':
            image = image.convert('RGB')
        
        # åˆ›å»ºä¸€ä¸ª BytesIO å¯¹è±¡æ¥ä¿å­˜å‹ç¼©åçš„å›¾ç‰‡
        output = BytesIO()
        
        # å°†å›¾ç‰‡ä¿å­˜ä¸º JPEG æ ¼å¼ï¼Œå¹¶è®¾ç½®å‹ç¼©è´¨é‡
        image.save(output, format="JPEG", quality=quality)
        
        # è¿”å›å‹ç¼©åçš„å›¾ç‰‡äºŒè¿›åˆ¶æ•°æ®
        output.seek(0)
        print('å‹ç¼©æˆåŠŸ')
        return output.read()
    
    except Exception as e:
        print(f"å›¾ç‰‡å‹ç¼©å¤±è´¥: {e}")
        return img_data  # å¦‚æœå‹ç¼©å¤±è´¥ï¼Œè¿”å›åŸå§‹å›¾åƒæ•°æ®
# è·å–ä»“åº“çš„é»˜è®¤åˆ†æ”¯
def get_default_branch(input_url):
    # ä½¿ç”¨ GitHub API è·å–ä»“åº“ä¿¡æ¯
    url = f"https://api.github.com/repos/{owner}/{repo}"
    response = requests.get(input_url)
    if response.status_code == 200:
        data = response.json()
        return data.get('default_branch', 'main')  # å¦‚æœæ²¡æœ‰è¿”å›é»˜è®¤åˆ†æ”¯ï¼Œåˆ™ä½¿ç”¨ 'main'
    else:
        raise Exception(f"æ— æ³•è·å–ä»“åº“ä¿¡æ¯ï¼ŒçŠ¶æ€ç : {response.status_code}")

# å®šä¹‰ç”Ÿæˆæ€»ç»“çš„å¼‚æ­¥å‡½æ•°
async def generate_summary(url: str):
    async with AsyncWebCrawler(verbose=True) as crawler:
        result = await crawler.arun(url=url)

        # å‡è®¾ `result.markdown_v2.raw_markdown` æ˜¯ä½ çš„åŸå§‹markdownå­—ç¬¦ä¸²
        raw_markdown = result.markdown_v2.raw_markdown

        # æ­£åˆ™è¡¨è¾¾å¼æå–ä»ç¬¬ä¸€ä¸ªæ ‡é¢˜åˆ°â€œ36æ°ªç»æˆæƒå‘å¸ƒâ€ä¹‹å‰çš„æ‰€æœ‰æ­£æ–‡å†…å®¹
        # text_content = re.findall(r'##?.*?([\s\S]+?)(?=36æ°ªç»æˆæƒå‘å¸ƒ)', raw_markdown)
        # text_content = re.findall(r'##?\s?.*?([\s\S]+?)(?=36æ°ªç»æˆæƒå‘å¸ƒ|åŸåˆ›å‡ºå“|(?=##))', raw_markdown)
        text_content = re.findall(r'lines[\s\S]*?([\s\S]+?)(?=36æ°ªç»æˆæƒå‘å¸ƒ|åŸåˆ›å‡ºå“|## Footer|\Z)', raw_markdown)
        print(text_content[:500])
        if text_content:
            body = "\n".join(text_content).strip()
        else:
            body = "æœªæ‰¾åˆ°æ­£æ–‡éƒ¨åˆ†"

        # é€šè¿‡ Google Gemini æ¨¡å‹ç”Ÿæˆæ€»ç»“
        try:
            model = genai.GenerativeModel("gemini-1.5-flash")
            summary_response = model.generate_content(f"ç”¨ä¸­æ–‡æ€»ç»“ä¸‹é¢çš„æ–‡ç« ï¼Œå¦‚æœæœ‰å›¾ç‰‡åœ°å€ï¼Œä¸€èµ·ä¿ç•™ç»™æˆ‘: {body}")
            return summary_response.text
        except Exception as e:
            print(f"ç”Ÿæˆæ€»ç»“æ—¶å‡ºé”™: {e}")
            return "æœªèƒ½ç”Ÿæˆæ€»ç»“"
# åˆ›å»ºç¿»è¯‘å™¨å®ä¾‹
translator = GoogleTranslator(source='en', target='zh-CN')

# ä»ç¯å¢ƒå˜é‡ä¸­è¯»å– API å¯†é’¥
api_key = os.getenv("GOOGLE_API_KEY")
genai.configure(api_key=api_key)
# å®šä¹‰ URL
URL = "https://github.com/trending?since=daily"

# å‘é€ HTTP GET è¯·æ±‚
response = requests.get(URL)
# ç¡®è®¤è¯·æ±‚æˆåŠŸ
if response.status_code == 200:
    # ä½¿ç”¨ BeautifulSoup è§£æ HTML é¡µé¢
    soup = BeautifulSoup(response.text, 'html.parser')
    
    repositories = []

    # æ‰¾åˆ°æ‰€æœ‰classä¸º'Box-row'çš„'article'æ ‡ç­¾ï¼Œæ¯ä¸ª'article'ä»£è¡¨ä¸€ä¸ªä»“åº“
    for article in soup.find_all('article', class_='Box-row'):
        # è·å–ä»“åº“åç§°å’Œé“¾æ¥ï¼ˆåœ¨'h2'ä¸­çš„'a'æ ‡ç­¾é‡Œï¼‰
        name_tag = article.find('h2', class_='h3 lh-condensed').find('a')
        repo_name = name_tag.get_text(strip=True)
        repo_url = f"https://github.com{name_tag['href']}"

        # è·å–ä»“åº“æè¿°ï¼ˆåœ¨'p'æ ‡ç­¾ä¸­ï¼‰
        description_tag = article.find('p', class_=lambda x: x != 'f6 color-fg-muted mt-2')
        if description_tag:
            description = description_tag.get_text(strip=True)
            # ä½¿ç”¨ deep_translator è¿›è¡Œç¿»è¯‘
            try:
                translated_description = translator.translate(description)
            except Exception as e:
                print(f"ç¿»è¯‘å¤±è´¥: {e}")
                translated_description = description
        else:
            translated_description = "æš‚æ— æè¿°"
        
        # è·å–ç¼–ç¨‹è¯­è¨€ï¼ˆåœ¨'span'å…ƒç´ ä¸­ï¼Œå…·æœ‰'itemprop'å±æ€§ï¼‰
        language_tag = article.find('span', itemprop='programmingLanguage')
        if language_tag:
            language = language_tag.get_text(strip=True)
        else:
            language = "æœªçŸ¥è¯­è¨€"
        
        # è·å–æ˜Ÿæ ‡æ•°ï¼ˆåœ¨'href'å±æ€§åŒ…å«'stargazers'çš„'a'æ ‡ç­¾é‡Œï¼‰
        stars_tag = article.find('a', href=lambda x: x and 'stargazers' in x)
        if stars_tag:
            stars = stars_tag.get_text(strip=True).replace(',', '')
            stars = int(stars) if stars.isdigit() else 0
        else:
            stars = 0
        
        # å°†ä»“åº“ä¿¡æ¯æ·»åŠ åˆ°åˆ—è¡¨ä¸­
        repositories.append({
            'repo_name': repo_name,
            'repo_url': repo_url,
            'description': translated_description,
            'language': language,
            'stars': stars
        })
    #æ„å»ºé‚®ä»¶å†…å®¹
    email_content = ""
    # æ ¹æ®æ˜Ÿæ ‡æ•°å¯¹åˆ—è¡¨è¿›è¡Œæ’åºï¼ˆé™åºï¼‰
    sorted_repositories = sorted(repositories, key=lambda x: x['stars'], reverse=True)
    
    #  response = requests.get(url, verify=False)

    for repo in sorted_repositories:
        email_content += f'##ğŸ“¦ é¡¹ç›®åç§°: {repo["repo_name"]}\n'
        email_content += f'ğŸ”— åœ°å€: {repo["repo_url"]}\n'
        email_content += f'ğŸ“ æè¿°: {repo["description"]}\n'
        email_content += f'ğŸ’» ä½¿ç”¨çš„è¯­è¨€: {repo["language"]}\n'
        email_content += f'â­ æœ¬å‘¨çš„æ”¶è—é‡: {repo["stars"]}\n'

        owner, repop = extract_owner_repo(repo["repo_url"])
        
            
        # readme_url = f"https://github.com/{owner}/{repo}/blob/{default_branch}/README.md"
        if owner and repop:
            default_branch = get_default_branch(repo["repo_url"])
            print(f"æå–åˆ°çš„ owner: {owner}, repo: {repop}")
            # readme_content = get_github_readme(owner, repop)
            url = f'{repo["repo_url"]}/blob/{default_branch}/README.md'  # ä½¿ç”¨ raw æ¥è·å–åŸå§‹ Markdown æ–‡ä»¶

            print(url)
            # è°ƒç”¨å¼‚æ­¥å‡½æ•°ç”Ÿæˆæ€»ç»“
            summary = asyncio.run(generate_summary(url))
        
            # if readme_content:
              
            #     image_links = extract_image_links(readme_content)
            # else:
            #     print("æœªæ‰¾åˆ° README å†…å®¹")
        else:
            summary="æ— æ³•ä» URL ä¸­æå– "
            print("æ— æ³•ä» URL ä¸­æå– owner å’Œ repo")
         # é€šè¿‡ Google Gemini æ¨¡å‹ç”Ÿæˆæ€»ç»“
         
          
        email_content += f'â­ README å†…å®¹: {summary}\n'
        # email_content += f'â­ å›¾ç‰‡åœ°å€: {image_links}\n'
        email_content += '\n'
        

    # é‚®ä»¶å‘é€é…ç½®
    sender_email = "386857251@qq.com"  # ä½¿ç”¨ç¯å¢ƒå˜é‡
    sender_password = "qosozmmhfzyybhgi"  # ä½¿ç”¨ç¯å¢ƒå˜é‡
    recipient_email = "zhengxinlilili@gmail.com"  # ä½¿ç”¨ç¯å¢ƒå˜é‡

    # åˆ›å»ºé‚®ä»¶å¯¹è±¡
    message = MIMEMultipart()
    message["From"] = sender_email
    message["To"] = recipient_email
    message["Subject"] = "æ¯æ—¥ GitHub Trending ä»“åº“"

    # é™„åŠ æ–‡æœ¬å†…å®¹
    message.attach(MIMEText(email_content, "plain", "utf-8"))

    try:
        # è¿æ¥åˆ° QQ é‚®ç®±çš„ SMTP æœåŠ¡å™¨
        with smtplib.SMTP("smtp.qq.com", 587) as server:
            server.starttls()  # å¯ç”¨åŠ å¯†ä¼ è¾“
            server.login(sender_email, sender_password)  # ç™»å½•
            server.sendmail(sender_email, recipient_email, message.as_string())  # å‘é€é‚®ä»¶

        print("é‚®ä»¶å‘é€æˆåŠŸï¼")
    except Exception as e:
        print(f"é‚®ä»¶å‘é€å¤±è´¥: {e}")

else:
    print("è·å–é¡µé¢å¤±è´¥")
